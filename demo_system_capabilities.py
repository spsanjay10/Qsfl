#!/usr/bin/env python3
"""
QSFL-CAAD System Capabilities Demonstration

This script demonstrates the key capabilities of the Quantum-Safe Federated Learning
with Client Anomaly and Attack Detection (QSFL-CAAD) system, including:

1. Post-quantum cryptographic security
2. Client authentication and authorization
3. AI-driven anomaly detection
4. Secure federated learning with attack mitigation
5. Real-time monitoring and alerting

Usage:
    python demo_system_capabilities.py [--scenario SCENARIO] [--verbose] [--save-results]

Scenarios:
    - basic: Basic federated learning with honest clients
    - mixed: Mixed honest and malicious clients
    - attack: Heavy attack scenario
    - all: Run all scenarios
"""

import argparse
import json
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from datetime import datetime
from typing import Dict, List, Any, Tuple
import tempfile
import os

# Import system components
from pq_security.manager import PQCryptoManager
from pq_security.kyber import KyberKeyExchange
from pq_security.dilithium import DilithiumSigner
from auth.authentication_service import AuthenticationService
from auth.credential_manager import ClientCredentialManager
from auth.revocation_manager import RevocationManager
from anomaly_detection.isolation_forest_detector import IsolationForestDetector
from anomaly_detection.feature_extractor import FeatureExtractor
from anomaly_detection.shap_explainer import SHAPExplainer
from anomaly_detection.reputation_manager import ClientReputationManager
from federated_learning.server import SecureFederatedServer
from federated_learning.model_aggregator import FederatedAveragingAggregator
from federated_learning.client_simulation import HonestClient, MaliciousClient, AttackType
from federated_learning.dataset_manager import DatasetManager, DatasetType, DistributionType
from monitoring.security_logger import SecurityEventLogger
from monitoring.metrics_collector import MetricsCollector
from monitoring.alert_manager import AlertManager

# Import test utilities
from tests.test_utils import ModelUpdateGenerator, create_test_model_shape


class SystemDemo:
    """Main demonstration class for QSFL-CAAD system."""
    
    def __init__(self, verbose: bool = False, save_results: bool = False):
        """Initialize the demonstration system."""
        self.verbose = verbose
        self.save_results = save_results
        self.results = {}
        self.temp_dir = tempfile.mkdtemp()
        
        # Initialize system components
        self._setup_system()
        
        print("üîê QSFL-CAAD System Demonstration")
        print("=" * 50)
        print(f"Temporary directory: {self.temp_dir}")
        print()
    
    def _setup_system(self):
        """Set up all system components."""
        # Post-quantum cryptography
        self.kyber = KyberKeyExchange()
        self.dilithium = DilithiumSigner()
        self.pq_crypto = PQCryptoManager(self.kyber, self.dilithium)
        
        # Authentication components
        self.credential_manager = ClientCredentialManager(self.pq_crypto)
        self.revocation_manager = RevocationManager(storage_path=self.temp_dir)
        self.auth_service = AuthenticationService(
            credential_manager=self.credential_manager,
            revocation_manager=self.revocation_manager,
            pq_crypto=self.pq_crypto
        )
        
        # Anomaly detection components
        self.feature_extractor = FeatureExtractor()
        self.anomaly_detector = IsolationForestDetector(self.feature_extractor)
        self.shap_explainer = SHAPExplainer(self.anomaly_detector, self.feature_extractor)
        self.reputation_manager = ClientReputationManager()
        
        # Monitoring components
        self.security_logger = SecurityEventLogger(
            log_file=os.path.join(self.temp_dir, "security_events.log")
        )
        self.metrics_collector = MetricsCollector(
            db_path=os.path.join(self.temp_dir, "metrics.db")
        )
        self.alert_manager = AlertManager(self.security_logger)
        
        # Federated learning components
        self.aggregator = FederatedAveragingAggregator()
        self.federated_server = SecureFederatedServer(
            auth_service=self.auth_service,
            pq_crypto=self.pq_crypto,
            aggregator=self.aggregator,
            anomaly_detector=self.anomaly_detector,
            reputation_manager=self.reputation_manager,
            security_logger=self.security_logger,
            metrics_collector=self.metrics_collector,
            alert_manager=self.alert_manager
        )
        
        # Utility components
        self.update_generator = ModelUpdateGenerator(seed=42)
        self.model_shape = create_test_model_shape("medium")
    
    def demonstrate_post_quantum_security(self) -> Dict[str, Any]:
        """Demonstrate post-quantum cryptographic capabilities."""
        print("üîë Demonstrating Post-Quantum Security")
        print("-" * 40)
        
        results = {}
        
        # Key generation
        print("1. Generating quantum-safe keypairs...")
        start_time = datetime.now()
        
        keypairs = []
        for i in range(5):
            public_key, private_key = self.pq_crypto.generate_keypair()
            keypairs.append((public_key, private_key))
            if self.verbose:
                print(f"   Keypair {i+1}: Public key size = {len(public_key)} bytes")
        
        keygen_time = (datetime.now() - start_time).total_seconds()
        print(f"   ‚úì Generated 5 keypairs in {keygen_time:.3f} seconds")
        
        # Digital signatures
        print("\n2. Testing digital signatures...")
        test_message = b"Federated learning model update data"
        
        signatures = []
        start_time = datetime.now()
        
        for i, (public_key, private_key) in enumerate(keypairs):
            signature = self.pq_crypto.sign(test_message, private_key)
            is_valid = self.pq_crypto.verify(test_message, signature, public_key)
            signatures.append((signature, is_valid))
            
            if self.verbose:
                print(f"   Signature {i+1}: Size = {len(signature)} bytes, Valid = {is_valid}")
        
        signing_time = (datetime.now() - start_time).total_seconds()
        all_valid = all(valid for _, valid in signatures)
        print(f"   ‚úì Signed and verified 5 messages in {signing_time:.3f} seconds")
        print(f"   ‚úì All signatures valid: {all_valid}")
        
        # Key exchange simulation
        print("\n3. Simulating key exchange...")
        client_public, client_private = keypairs[0]
        server_public, server_private = keypairs[1]
        
        # Simulate Kyber key encapsulation
        try:
            ciphertext, shared_secret1 = self.kyber.encapsulate(server_public)
            shared_secret2 = self.kyber.decapsulate(ciphertext, server_private)
            
            key_exchange_success = shared_secret1 == shared_secret2
            print(f"   ‚úì Key exchange successful: {key_exchange_success}")
            print(f"   ‚úì Shared secret size: {len(shared_secret1)} bytes")
            
        except Exception as e:
            print(f"   ‚ö† Key exchange simulation: {str(e)}")
            key_exchange_success = False
        
        results = {
            'keypair_generation_time': keygen_time,
            'signing_verification_time': signing_time,
            'all_signatures_valid': all_valid,
            'key_exchange_success': key_exchange_success,
            'average_signature_size': np.mean([len(sig) for sig, _ in signatures]),
            'average_public_key_size': np.mean([len(pub) for pub, _ in keypairs])
        }
        
        print(f"\n‚úÖ Post-quantum security demonstration completed")
        return results
    
    def demonstrate_client_authentication(self) -> Dict[str, Any]:
        """Demonstrate client authentication and authorization."""
        print("\nüîê Demonstrating Client Authentication")
        print("-" * 40)
        
        results = {}
        
        # Register multiple clients
        print("1. Registering clients...")
        clients = ["honest_client_001", "honest_client_002", "malicious_client_001"]
        client_credentials = {}
        
        registration_times = []
        for client_id in clients:
            start_time = datetime.now()
            credentials = self.auth_service.register_client(client_id)
            registration_time = (datetime.now() - start_time).total_seconds()
            registration_times.append(registration_time)
            
            client_credentials[client_id] = credentials
            print(f"   ‚úì Registered {client_id} in {registration_time:.3f}s")
        
        # Test authentication
        print("\n2. Testing authentication...")
        test_message = b"model_update_round_001"
        auth_results = {}
        
        for client_id, credentials in client_credentials.items():
            # Sign message with client's private key
            signature = self.pq_crypto.sign(test_message, credentials.private_key)
            
            # Authenticate using the service
            is_authenticated = self.auth_service.authenticate_client(
                client_id, signature, test_message
            )
            auth_results[client_id] = is_authenticated
            
            status = "‚úì Authenticated" if is_authenticated else "‚úó Failed"
            print(f"   {status}: {client_id}")
        
        # Test revocation
        print("\n3. Testing credential revocation...")
        revoked_client = "malicious_client_001"
        self.auth_service.revoke_client(revoked_client)
        
        is_valid_after_revocation = self.auth_service.is_client_valid(revoked_client)
        print(f"   ‚úì Revoked {revoked_client}")
        print(f"   ‚úì Client valid after revocation: {is_valid_after_revocation}")
        
        # Test authentication after revocation
        signature = self.pq_crypto.sign(test_message, client_credentials[revoked_client].private_key)
        auth_after_revocation = self.auth_service.authenticate_client(
            revoked_client, signature, test_message
        )
        print(f"   ‚úì Authentication after revocation: {auth_after_revocation}")
        
        results = {
            'clients_registered': len(clients),
            'average_registration_time': np.mean(registration_times),
            'authentication_success_rate': sum(auth_results.values()) / len(auth_results),
            'revocation_effective': not is_valid_after_revocation,
            'auth_blocked_after_revocation': not auth_after_revocation
        }
        
        print(f"\n‚úÖ Client authentication demonstration completed")
        return results
    
    def demonstrate_anomaly_detection(self) -> Dict[str, Any]:
        """Demonstrate AI-driven anomaly detection."""
        print("\nü§ñ Demonstrating AI-Driven Anomaly Detection")
        print("-" * 40)
        
        results = {}
        
        # Generate training data
        print("1. Training anomaly detector...")
        normal_updates = []
        for i in range(50):
            update = self.update_generator.generate_honest_update(
                f"training_client_{i}", "training_round", self.model_shape
            )
            normal_updates.append(update)
        
        start_time = datetime.now()
        self.anomaly_detector.fit(normal_updates)
        training_time = (datetime.now() - start_time).total_seconds()
        print(f"   ‚úì Trained on {len(normal_updates)} normal updates in {training_time:.3f}s")
        
        # Test detection on normal updates
        print("\n2. Testing detection on normal updates...")
        normal_scores = []
        for i in range(10):
            update = self.update_generator.generate_honest_update(
                f"test_honest_{i}", "test_round", self.model_shape
            )
            score = self.anomaly_detector.predict_anomaly_score(update)
            normal_scores.append(score)
        
        avg_normal_score = np.mean(normal_scores)
        print(f"   ‚úì Average anomaly score for normal updates: {avg_normal_score:.3f}")
        
        # Test detection on malicious updates
        print("\n3. Testing detection on malicious updates...")
        attack_types = ["gradient_poisoning", "model_replacement", "byzantine", "backdoor"]
        attack_results = {}
        
        for attack_type in attack_types:
            malicious_update = self.update_generator.generate_malicious_update(
                f"attacker_{attack_type}", "test_round", self.model_shape,
                attack_type=attack_type, attack_intensity=2.0
            )
            
            score = self.anomaly_detector.predict_anomaly_score(malicious_update)
            detected = score > 0.5  # Detection threshold
            
            attack_results[attack_type] = {
                'anomaly_score': score,
                'detected': detected
            }
            
            status = "üö® DETECTED" if detected else "‚ö† Missed"
            print(f"   {status}: {attack_type} (score: {score:.3f})")
        
        # Test SHAP explanations
        print("\n4. Generating explanations for detected attacks...")
        explanations = {}
        
        for attack_type, result in attack_results.items():
            if result['detected']:
                malicious_update = self.update_generator.generate_malicious_update(
                    f"attacker_{attack_type}", "test_round", self.model_shape,
                    attack_type=attack_type, attack_intensity=2.0
                )
                
                try:
                    explanation = self.shap_explainer.explain(
                        malicious_update, result['anomaly_score']
                    )
                    explanations[attack_type] = explanation
                    
                    top_features = sorted(explanation.items(), key=lambda x: abs(x[1]), reverse=True)[:3]
                    print(f"   üìä {attack_type} top features: {top_features}")
                    
                except Exception as e:
                    print(f"   ‚ö† Explanation failed for {attack_type}: {str(e)}")
        
        # Test reputation management
        print("\n5. Testing reputation management...")
        test_client = "reputation_test_client"
        initial_reputation = self.reputation_manager.get_reputation(test_client)
        
        # Simulate multiple anomalous updates
        for i in range(3):
            high_score = 0.8 + (i * 0.05)  # Increasing anomaly scores
            self.reputation_manager.update_reputation(test_client, high_score)
        
        final_reputation = self.reputation_manager.get_reputation(test_client)
        is_quarantined = self.reputation_manager.is_quarantined(test_client)
        
        print(f"   ‚úì Initial reputation: {initial_reputation:.3f}")
        print(f"   ‚úì Final reputation: {final_reputation:.3f}")
        print(f"   ‚úì Client quarantined: {is_quarantined}")
        
        results = {
            'training_time': training_time,
            'training_samples': len(normal_updates),
            'avg_normal_score': avg_normal_score,
            'attack_detection_rate': sum(1 for r in attack_results.values() if r['detected']) / len(attack_results),
            'attack_results': attack_results,
            'explanations_generated': len(explanations),
            'reputation_degradation': initial_reputation - final_reputation,
            'quarantine_triggered': is_quarantined
        }
        
        print(f"\n‚úÖ Anomaly detection demonstration completed")
        return results
    
    def demonstrate_federated_learning(self, scenario: str = "mixed") -> Dict[str, Any]:
        """Demonstrate secure federated learning with different scenarios."""
        print(f"\nü§ù Demonstrating Federated Learning ({scenario.upper()} scenario)")
        print("-" * 40)
        
        results = {}
        
        # Initialize global model
        print("1. Initializing global model...")
        initial_weights = {name: np.zeros(shape, dtype=np.float32) 
                          for name, shape in self.model_shape.items()}
        global_model = self.federated_server.initialize_global_model(initial_weights)
        print(f"   ‚úì Initialized model with ID: {global_model.model_id}")
        
        # Define scenario parameters
        scenarios = {
            "basic": {"honest": 5, "malicious": 0, "rounds": 3},
            "mixed": {"honest": 7, "malicious": 3, "rounds": 5},
            "attack": {"honest": 3, "malicious": 7, "rounds": 3}
        }
        
        params = scenarios.get(scenario, scenarios["mixed"])
        
        # Register clients
        print(f"\n2. Registering {params['honest']} honest and {params['malicious']} malicious clients...")
        honest_clients = [f"honest_{i:03d}" for i in range(params['honest'])]
        malicious_clients = [f"malicious_{i:03d}" for i in range(params['malicious'])]
        all_clients = honest_clients + malicious_clients
        
        client_credentials = {}
        for client_id in all_clients:
            credentials = self.auth_service.register_client(client_id)
            client_credentials[client_id] = credentials
        
        print(f"   ‚úì Registered {len(all_clients)} clients")
        
        # Train anomaly detector if there are malicious clients
        if params['malicious'] > 0:
            print("\n3. Training anomaly detector...")
            training_updates = []
            for i in range(30):
                update = self.update_generator.generate_honest_update(
                    f"training_{i}", "training", self.model_shape
                )
                training_updates.append(update)
            
            self.anomaly_detector.fit(training_updates)
            print(f"   ‚úì Trained detector on {len(training_updates)} samples")
        
        # Run federated learning rounds
        print(f"\n4. Running {params['rounds']} federated learning rounds...")
        round_results = []
        
        for round_num in range(params['rounds']):
            print(f"\n   Round {round_num + 1}/{params['rounds']}:")
            
            # Start round
            round_id = self.federated_server.start_training_round()
            
            # Submit honest client updates
            honest_accepted = 0
            for client_id in honest_clients:
                update = self.update_generator.generate_honest_update(
                    client_id, round_id, self.model_shape
                )
                
                # Sign the update
                message = f"{client_id}:{round_id}".encode()
                signature = self.pq_crypto.sign(message, client_credentials[client_id].private_key)
                update.signature = signature
                
                if self.federated_server.receive_client_update(client_id, update):
                    honest_accepted += 1
            
            # Submit malicious client updates
            malicious_accepted = 0
            malicious_detected = 0
            
            for client_id in malicious_clients:
                attack_type = np.random.choice(["gradient_poisoning", "model_replacement", "byzantine"])
                update = self.update_generator.generate_malicious_update(
                    client_id, round_id, self.model_shape,
                    attack_type=attack_type, attack_intensity=np.random.uniform(1.0, 3.0)
                )
                
                # Sign the update
                message = f"{client_id}:{round_id}".encode()
                signature = self.pq_crypto.sign(message, client_credentials[client_id].private_key)
                update.signature = signature
                
                # Check if detected as anomalous
                anomaly_score = self.anomaly_detector.predict_anomaly_score(update)
                if anomaly_score > 0.5:
                    malicious_detected += 1
                
                if self.federated_server.receive_client_update(client_id, update):
                    malicious_accepted += 1
            
            # Aggregate updates
            try:
                new_global_model = self.federated_server.aggregate_updates(round_id)
                aggregation_success = True
                
                # Calculate model change
                model_change = 0.0
                for layer_name in initial_weights.keys():
                    if layer_name in new_global_model.weights:
                        change = np.sum(np.abs(new_global_model.weights[layer_name] - 
                                             global_model.weights[layer_name]))
                        model_change += change
                
                global_model = new_global_model
                
            except Exception as e:
                aggregation_success = False
                model_change = 0.0
                print(f"     ‚ö† Aggregation failed: {str(e)}")
            
            round_result = {
                'round_id': round_id,
                'honest_accepted': honest_accepted,
                'malicious_accepted': malicious_accepted,
                'malicious_detected': malicious_detected,
                'aggregation_success': aggregation_success,
                'model_change': model_change
            }
            round_results.append(round_result)
            
            print(f"     ‚úì Honest updates accepted: {honest_accepted}/{len(honest_clients)}")
            print(f"     üö® Malicious updates detected: {malicious_detected}/{len(malicious_clients)}")
            print(f"     ‚úì Aggregation successful: {aggregation_success}")
            
        # Calculate final statistics
        total_honest_accepted = sum(r['honest_accepted'] for r in round_results)
        total_malicious_detected = sum(r['malicious_detected'] for r in round_results)
        total_malicious_submitted = len(malicious_clients) * params['rounds']
        successful_rounds = sum(1 for r in round_results if r['aggregation_success'])
        
        detection_rate = total_malicious_detected / total_malicious_submitted if total_malicious_submitted > 0 else 1.0
        
        results = {
            'scenario': scenario,
            'honest_clients': len(honest_clients),
            'malicious_clients': len(malicious_clients),
            'total_rounds': params['rounds'],
            'successful_rounds': successful_rounds,
            'total_honest_accepted': total_honest_accepted,
            'total_malicious_detected': total_malicious_detected,
            'detection_rate': detection_rate,
            'round_results': round_results,
            'final_model_id': global_model.model_id if global_model else None
        }
        
        print(f"\n   üìä Final Statistics:")
        print(f"     ‚Ä¢ Detection rate: {detection_rate:.1%}")
        print(f"     ‚Ä¢ Successful rounds: {successful_rounds}/{params['rounds']}")
        print(f"     ‚Ä¢ Total honest updates accepted: {total_honest_accepted}")
        
        print(f"\n‚úÖ Federated learning demonstration completed")
        return results
    
    def demonstrate_monitoring_and_alerts(self) -> Dict[str, Any]:
        """Demonstrate monitoring and alerting capabilities."""
        print("\nüìä Demonstrating Monitoring and Alerting")
        print("-" * 40)
        
        results = {}
        
        # Generate some security events
        print("1. Generating security events...")
        
        # Simulate authentication events
        self.security_logger.log_authentication_event("client_001", True, "successful_login")
        self.security_logger.log_authentication_event("client_002", False, "invalid_signature")
        
        # Simulate anomaly detection events
        self.security_logger.log_anomaly_detection("client_003", 0.8, "gradient_poisoning_detected")
        self.security_logger.log_anomaly_detection("client_004", 0.9, "model_replacement_detected")
        
        print("   ‚úì Generated authentication and anomaly detection events")
        
        # Collect metrics
        print("\n2. Collecting system metrics...")
        
        # Simulate some metrics
        self.metrics_collector.record_metric("round_completion_time", 2.5, {"round_id": "demo_round_001"})
        self.metrics_collector.record_metric("client_count", 10, {"round_id": "demo_round_001"})
        self.metrics_collector.record_metric("anomaly_detection_rate", 0.2, {"round_id": "demo_round_001"})
        
        print("   ‚úì Recorded performance and security metrics")
        
        # Test alert generation
        print("\n3. Testing alert generation...")
        
        # Simulate conditions that should trigger alerts
        alert_conditions = [
            ("high_anomaly_rate", {"anomaly_rate": 0.8, "threshold": 0.5}),
            ("authentication_failures", {"failure_count": 5, "time_window": "1min"}),
            ("model_divergence", {"divergence_score": 0.9, "threshold": 0.7})
        ]
        
        alerts_generated = []
        for alert_type, context in alert_conditions:
            try:
                alert = self.alert_manager.generate_alert(
                    alert_type=alert_type,
                    severity="HIGH",
                    message=f"Alert condition detected: {alert_type}",
                    context=context
                )
                alerts_generated.append(alert)
                print(f"   üö® Generated alert: {alert_type}")
                
            except Exception as e:
                print(f"   ‚ö† Alert generation failed for {alert_type}: {str(e)}")
        
        # Query recent events
        print("\n4. Querying recent events...")
        
        try:
            # This would query the actual log files/database
            recent_events_count = 4  # Simulated count
            print(f"   ‚úì Found {recent_events_count} recent security events")
            
        except Exception as e:
            print(f"   ‚ö† Event query failed: {str(e)}")
            recent_events_count = 0
        
        results = {
            'security_events_logged': 4,
            'metrics_recorded': 3,
            'alerts_generated': len(alerts_generated),
            'recent_events_count': recent_events_count,
            'monitoring_active': True
        }
        
        print(f"\n‚úÖ Monitoring and alerting demonstration completed")
        return results
    
    def run_scenario(self, scenario: str) -> Dict[str, Any]:
        """Run a complete demonstration scenario."""
        print(f"\nüéØ Running {scenario.upper()} Scenario")
        print("=" * 60)
        
        scenario_results = {}
        
        # Always demonstrate core capabilities
        scenario_results['post_quantum_security'] = self.demonstrate_post_quantum_security()
        scenario_results['client_authentication'] = self.demonstrate_client_authentication()
        scenario_results['anomaly_detection'] = self.demonstrate_anomaly_detection()
        scenario_results['monitoring_alerts'] = self.demonstrate_monitoring_and_alerts()
        
        # Scenario-specific federated learning demonstration
        if scenario == "basic":
            scenario_results['federated_learning'] = self.demonstrate_federated_learning("basic")
        elif scenario == "mixed":
            scenario_results['federated_learning'] = self.demonstrate_federated_learning("mixed")
        elif scenario == "attack":
            scenario_results['federated_learning'] = self.demonstrate_federated_learning("attack")
        elif scenario == "all":
            scenario_results['federated_learning_basic'] = self.demonstrate_federated_learning("basic")
            scenario_results['federated_learning_mixed'] = self.demonstrate_federated_learning("mixed")
            scenario_results['federated_learning_attack'] = self.demonstrate_federated_learning("attack")
        
        return scenario_results
    
    def generate_summary_report(self, results: Dict[str, Any]) -> str:
        """Generate a summary report of the demonstration."""
        report = []
        report.append("QSFL-CAAD System Demonstration Summary")
        report.append("=" * 50)
        report.append(f"Timestamp: {datetime.now().isoformat()}")
        report.append("")
        
        # Post-quantum security summary
        if 'post_quantum_security' in results:
            pq_results = results['post_quantum_security']
            report.append("üîë Post-Quantum Security:")
            report.append(f"  ‚Ä¢ Key generation time: {pq_results['keypair_generation_time']:.3f}s")
            report.append(f"  ‚Ä¢ Signature verification time: {pq_results['signing_verification_time']:.3f}s")
            report.append(f"  ‚Ä¢ All signatures valid: {pq_results['all_signatures_valid']}")
            report.append(f"  ‚Ä¢ Key exchange successful: {pq_results['key_exchange_success']}")
            report.append("")
        
        # Authentication summary
        if 'client_authentication' in results:
            auth_results = results['client_authentication']
            report.append("üîê Client Authentication:")
            report.append(f"  ‚Ä¢ Clients registered: {auth_results['clients_registered']}")
            report.append(f"  ‚Ä¢ Authentication success rate: {auth_results['authentication_success_rate']:.1%}")
            report.append(f"  ‚Ä¢ Revocation effective: {auth_results['revocation_effective']}")
            report.append("")
        
        # Anomaly detection summary
        if 'anomaly_detection' in results:
            ad_results = results['anomaly_detection']
            report.append("ü§ñ Anomaly Detection:")
            report.append(f"  ‚Ä¢ Training time: {ad_results['training_time']:.3f}s")
            report.append(f"  ‚Ä¢ Attack detection rate: {ad_results['attack_detection_rate']:.1%}")
            report.append(f"  ‚Ä¢ Average normal score: {ad_results['avg_normal_score']:.3f}")
            report.append(f"  ‚Ä¢ Explanations generated: {ad_results['explanations_generated']}")
            report.append("")
        
        # Federated learning summary
        fl_keys = [k for k in results.keys() if k.startswith('federated_learning')]
        for fl_key in fl_keys:
            fl_results = results[fl_key]
            scenario_name = fl_key.replace('federated_learning_', '').replace('federated_learning', 'mixed')
            report.append(f"ü§ù Federated Learning ({scenario_name.upper()}):")
            report.append(f"  ‚Ä¢ Scenario: {fl_results['scenario']}")
            report.append(f"  ‚Ä¢ Detection rate: {fl_results['detection_rate']:.1%}")
            report.append(f"  ‚Ä¢ Successful rounds: {fl_results['successful_rounds']}/{fl_results['total_rounds']}")
            report.append(f"  ‚Ä¢ Honest clients: {fl_results['honest_clients']}")
            report.append(f"  ‚Ä¢ Malicious clients: {fl_results['malicious_clients']}")
            report.append("")
        
        # Monitoring summary
        if 'monitoring_alerts' in results:
            mon_results = results['monitoring_alerts']
            report.append("üìä Monitoring & Alerting:")
            report.append(f"  ‚Ä¢ Security events logged: {mon_results['security_events_logged']}")
            report.append(f"  ‚Ä¢ Metrics recorded: {mon_results['metrics_recorded']}")
            report.append(f"  ‚Ä¢ Alerts generated: {mon_results['alerts_generated']}")
            report.append("")
        
        report.append("‚úÖ Demonstration completed successfully!")
        
        return "\n".join(report)
    
    def save_results(self, results: Dict[str, Any], filename: str = None):
        """Save demonstration results to file."""
        if not self.save_results:
            return
        
        if filename is None:
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            filename = f"qsfl_caad_demo_results_{timestamp}.json"
        
        try:
            # Convert numpy types to native Python types for JSON serialization
            def convert_numpy(obj):
                if isinstance(obj, np.ndarray):
                    return obj.tolist()
                elif isinstance(obj, np.floating):
                    return float(obj)
                elif isinstance(obj, np.integer):
                    return int(obj)
                elif isinstance(obj, dict):
                    return {k: convert_numpy(v) for k, v in obj.items()}
                elif isinstance(obj, list):
                    return [convert_numpy(item) for item in obj]
                else:
                    return obj
            
            serializable_results = convert_numpy(results)
            
            with open(filename, 'w') as f:
                json.dump(serializable_results, f, indent=2, default=str)
            
            print(f"\nüíæ Results saved to: {filename}")
            
        except Exception as e:
            print(f"\n‚ö† Failed to save results: {str(e)}")
    
    def cleanup(self):
        """Clean up temporary resources."""
        try:
            import shutil
            shutil.rmtree(self.temp_dir)
        except Exception as e:
            print(f"‚ö† Cleanup warning: {str(e)}")


def main():
    """Main demonstration function."""
    parser = argparse.ArgumentParser(
        description="QSFL-CAAD System Capabilities Demonstration",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
Scenarios:
  basic    - Basic federated learning with honest clients only
  mixed    - Mixed honest and malicious clients (default)
  attack   - Heavy attack scenario with majority malicious clients
  all      - Run all scenarios sequentially

Examples:
  python demo_system_capabilities.py --scenario mixed --verbose
  python demo_system_capabilities.py --scenario all --save-results
        """
    )
    
    parser.add_argument(
        '--scenario', 
        choices=['basic', 'mixed', 'attack', 'all'],
        default='mixed',
        help='Demonstration scenario to run (default: mixed)'
    )
    
    parser.add_argument(
        '--verbose', 
        action='store_true',
        help='Enable verbose output'
    )
    
    parser.add_argument(
        '--save-results', 
        action='store_true',
        help='Save demonstration results to JSON file'
    )
    
    args = parser.parse_args()
    
    # Initialize and run demonstration
    demo = SystemDemo(verbose=args.verbose, save_results=args.save_results)
    
    try:
        # Run the selected scenario
        results = demo.run_scenario(args.scenario)
        
        # Generate and display summary report
        summary = demo.generate_summary_report(results)
        print("\n" + summary)
        
        # Save results if requested
        if args.save_results:
            demo.save_results(results)
        
    except KeyboardInterrupt:
        print("\n\n‚ö† Demonstration interrupted by user")
    except Exception as e:
        print(f"\n\n‚ùå Demonstration failed: {str(e)}")
        if args.verbose:
            import traceback
            traceback.print_exc()
    finally:
        demo.cleanup()


if __name__ == "__main__":
    main()